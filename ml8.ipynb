{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25c8df66",
   "metadata": {},
   "source": [
    "# Bagged Decision Trees for Classification\n",
    "#begging --- dataset\n",
    "#boosting --prediction\n",
    "#stacking --results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce1dde98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.96 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=2020)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2020)\n",
    "max_features = 3\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=2020)\n",
    "decision_tree = DecisionTreeClassifier(max_features=max_features)\n",
    "num_trees = 100\n",
    "bagging_model = BaggingClassifier(base_estimator=decision_tree, n_estimators=num_trees,random_state=2020)\n",
    "results = cross_val_score(bagging_model, X_train, y_train, cv=kfold)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdb8565",
   "metadata": {},
   "source": [
    "# Decesion Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1bf371df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging Accuracy: 0.96 (+/- 0.01)\n",
      "Random Forest Accuracy: 0.96 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# Bagging Classifier\n",
    "max_features = 3\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=2020)\n",
    "# Decision Tree base estimator\n",
    "dt = DecisionTreeClassifier(max_features=max_features)\n",
    "num_trees = 100\n",
    "bagging_model = BaggingClassifier(base_estimator=dt, n_estimators=num_trees, random_state=2020)\n",
    "# Cross-validation\n",
    "results = cross_val_score(bagging_model, X_train, y_train, cv=kfold)\n",
    "print(\"Bagging Accuracy: %0.2f (+/- %0.2f)\" % (results.mean(), results.std()))\n",
    "# Random Forest Classifier\n",
    "num_trees_rf = 100\n",
    "max_features_rf = 3\n",
    "kfold_rf = KFold(n_splits=10, shuffle=True, random_state=2020)\n",
    "rf_model = RandomForestClassifier(n_estimators=num_trees_rf, max_features=max_features) \n",
    "num_trees=100\n",
    "# Cross-validation\n",
    "results_rf = cross_val_score(rf_model, X_train, y_train, cv=kfold_rf)\n",
    "print(\"Random Forest Accuracy: %0.2f (+/- %0.2f)\" % (results_rf.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a634a4d",
   "metadata": {},
   "source": [
    "# Adaboost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "65e23573",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Boosting: F1 Score 0.93, Accuracy 0.93\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "# Assuming train_x, train_y, test_x, test_y are your training and testing data\n",
    "# Adjust these names based on your actual data\n",
    "# Instantiate AdaBoostClassifier with DecisionTree base estimator\n",
    "clf_boosting = AdaBoostClassifier(\n",
    " base_estimator=DecisionTreeClassifier(max_depth=1),\n",
    " n_estimators=200\n",
    ")\n",
    "# Fit the model\n",
    "clf_boosting.fit(X_train, y_train)\n",
    "# Make predictions\n",
    "predictions = clf_boosting.predict(X_test)\n",
    "# Calculate and print F1 Score and Accuracy\n",
    "print(\"For Boosting: F1 Score {}, Accuracy {}\".format(\n",
    " round(f1_score(y_test, predictions), 2),\n",
    " round(accuracy_score(y_test, predictions), 2)\n",
    "))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a04f90",
   "metadata": {},
   "source": [
    "# Random Forest as a Bagging classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d09a5e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Bagging : F1 Score 0.75 , Accuracy 0.74 \n"
     ]
    }
   ],
   "source": [
    "clf_bagging = RandomForestClassifier(n_estimators=200 , max_depth= 1)\n",
    "clf_bagging.fit(train_x , train_y )\n",
    "predictions = clf_bagging.predict(test_x)\n",
    "print(\"For Bagging : F1 Score {} , Accuracy {} \".format(round( f1_score (test_y,predictions) ,2) ,\n",
    "                                                         round(accuracy_score (test_y , predictions ) ,2) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364ab1cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "825b9360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Random Forest: F1 Score 0.88, Accuracy 0.88\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "# Create a synthetic dataset\n",
    "X, y = make_classification(\n",
    " n_samples=800, # Total number of samples\n",
    " n_features=20, # Number of features\n",
    " n_informative=10, # Number of informative features\n",
    " n_redundant=5, # Number of redundant features\n",
    " n_clusters_per_class=2, # Number of clusters per class\n",
    " weights=[0.5, 0.5], # Class distribution (balanced)\n",
    " random_state=42\n",
    ")\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    " X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "# Model training using RandomForestClassifier as an example\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "# Make predictions\n",
    "predictions = rf_model.predict(X_test)\n",
    "# Calculate and print F1 Score and Accuracy\n",
    "print(\"For Random Forest: F1 Score {}, Accuracy {}\".format(\n",
    " round(f1_score(y_test, predictions), 2),\n",
    " round(accuracy_score(y_test, predictions), 2)\n",
    "))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d931912f",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1e349957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a synthetic dataset\n",
    "X, y = make_classification(\n",
    " n_samples=800, # Total number of samples\n",
    " n_features=20, # Number of features\n",
    " n_informative=10, # Number of informative features\n",
    " n_redundant=5, # Number of redundant features\n",
    " n_clusters_per_class=2, # Number of clusters per class\n",
    " weights=[0.5, 0.5], # Class distribution (balanced)\n",
    " random_state=42\n",
    ")\n",
    "# Split the dataset into training and testing sets\n",
    "train_x, test_x, train_y, test_y = train_test_split(\n",
    " X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "691101c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Bagging: F1 Score 0.73, Accuracy 0.72\n",
      "For Boosting: F1 Score 0.71, Accuracy 0.71\n",
      "For Stacking: F1 Score 0.81, Accuracy 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\ensemble\\_base.py:156: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "class NumberOfClassifierException(Exception):\n",
    "    pass\n",
    "class Stacking():\n",
    "    def __init__(self, classifiers):\n",
    "        if len(classifiers) < 2:\n",
    "            raise NumberOfClassifierException(\"You must fit your classifier with 2 classifiers at least \");\n",
    "        else:\n",
    "            self._classifiers = classifiers\n",
    "    def fit(self, data_x, data_y):\n",
    "        stacked_data_x = data_x.copy()\n",
    "        for classifier in self._classifiers[:-1]:\n",
    "            classifier.fit(data_x, data_y)\n",
    "            #stacked_data_x = np.column_stack((stacked_data_x, classifier.predic\n",
    "            stacked_data_x = np.column_stack((stacked_data_x ,classifier.predict_proba(data_x)))\n",
    " \n",
    "        last_classifier = self._classifiers[-1]\n",
    "        last_classifier.fit(stacked_data_x, data_y)\n",
    "    def predict(self, data_x):\n",
    "        stacked_data_x = data_x.copy()\n",
    "        for classifier in self._classifiers[:-1]:\n",
    "            prob_predictions = classifier.predict_proba(data_x)\n",
    "            #stacked_data_x = np.column_stack((stacked_data_x, prob_predictions)\n",
    "            stacked_data_x = np.column_stack((stacked_data_x, prob_predictions))\n",
    "        last_classifier = self._classifiers[-1]\n",
    "        return last_classifier.predict(stacked_data_x)\n",
    "# Creating classifiers\n",
    "boosting_clf_ada_boost = AdaBoostClassifier(\n",
    "base_estimator=DecisionTreeClassifier(max_depth=1),\n",
    "n_estimators=3\n",
    ")\n",
    "clf_rf = RandomForestClassifier(\n",
    "n_estimators=200,\n",
    "max_depth=1,\n",
    "random_state=2020\n",
    ")\n",
    "clf_adaboost = AdaBoostClassifier(\n",
    "base_estimator=DecisionTreeClassifier(max_depth=1, random_state=2020),\n",
    "n_estimators=3\n",
    ")\n",
    "clf_logistic_reg = LogisticRegression(solver='liblinear', random_state=2020)\n",
    "# Customizing and Exception message\n",
    "classifiers_list = [clf_rf, clf_adaboost, clf_logistic_reg]\n",
    "clf_stacking = Stacking(classifiers_list)\n",
    "# Fit models\n",
    "clf_rf.fit(train_x, train_y)\n",
    " \n",
    "boosting_clf_ada_boost.fit(train_x, train_y)\n",
    "clf_stacking.fit(train_x, train_y)\n",
    "# Make predictions\n",
    "predictions_bagging = clf_rf.predict(test_x)\n",
    "predictions_boosting = boosting_clf_ada_boost.predict(test_x)\n",
    "predictions_stacking = clf_stacking.predict(test_x)\n",
    "# Print results\n",
    "print(\"For Bagging: F1 Score {}, Accuracy {}\".format(\n",
    "round(f1_score(test_y, predictions_bagging), 2),\n",
    "round(accuracy_score(test_y, predictions_bagging), 2)\n",
    "))\n",
    "print(\"For Boosting: F1 Score {}, Accuracy {}\".format(\n",
    "round(f1_score(test_y, predictions_boosting), 2),\n",
    "round(accuracy_score(test_y, predictions_boosting), 2)\n",
    "))\n",
    "print(\"For Stacking: F1 Score {}, Accuracy {}\".format(\n",
    "round(f1_score(test_y, predictions_stacking), 2),\n",
    "round(accuracy_score(test_y, predictions_stacking), 2)\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be38213d",
   "metadata": {},
   "source": [
    "# LabTask\n",
    "1=Use BaggingClassifier and RandomForestClassifier from sklearn library and implement them\n",
    "on diabetes data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "412c27f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'diabetes' from 'sklearn.datasets' (C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\datasets\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaggingClassifier\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m diabetes \n\u001b[0;32m      5\u001b[0m data \u001b[38;5;241m=\u001b[39m load_diabetes()\n\u001b[0;32m      6\u001b[0m X_df \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mdata\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'diabetes' from 'sklearn.datasets' (C:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\datasets\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.datasets import diabetes \n",
    "data = load_diabetes()\n",
    "X_df = data.data\n",
    "y_train = data.target\n",
    "\n",
    "\n",
    "max_features = 3\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=2020)\n",
    "decision_tree = DecisionTreeClassifier(max_features=max_features)\n",
    "num_trees = 100\n",
    "bagging_model = BaggingClassifier(base_estimator=decision_tree, n_estimators=num_trees,random_state=2020)\n",
    "results = cross_val_score(bagging_model, X_train, y_train, cv=kfold)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a2b7b908",
   "metadata": {},
   "source": [
    "2=Compare the results of Task - 1 classification tasks using accuracy, F1, and confusion matrix"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b5aeb644",
   "metadata": {},
   "source": [
    "3. Use Use AdaBoostClassifier and RandomForstClassifier from sklearn library and implment both\n",
    "on Breast Cancer data set."
   ]
  },
  {
   "cell_type": "raw",
   "id": "a09add21",
   "metadata": {},
   "source": [
    "4. Compare the results of Task - 3 classification tasks using accuracy, F1, and confusion matrix."
   ]
  },
  {
   "cell_type": "raw",
   "id": "4ec85eb0",
   "metadata": {},
   "source": [
    "5. To check and compare the performance of Bagging, Boosting, and Stacking classification algorithms, implement AdaBoostClassifier, RandomForestClassifier, and LogisticRegrassion (for\n",
    "Stacking) on Breast Cancer data set"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1445cb18",
   "metadata": {},
   "source": [
    "6. Compare the results of Task - 5 classification tasks using accuracy, F1, and confusion matrix."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
